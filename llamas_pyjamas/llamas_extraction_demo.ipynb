{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing llamas_pyjamas modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please follow the installation instructions prior to attempting this**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pickle\n",
    "import ray\n",
    "import pkg_resources\n",
    "import glob\n",
    "import traceback\n",
    "from   pathlib import Path\n",
    "from   config import BASE_DIR, OUTPUT_DIR, DATA_DIR\n",
    "\n",
    "# Get package root and add to path before other imports as a precaution -> if installed as package this should hopefully not be needed\n",
    "package_root = Path().absolute().parent\n",
    "sys.path.append(str(package_root))\n",
    "sys.path.append(BASE_DIR+'/')\n",
    "\n",
    "\n",
    "ray.init(ignore_reinit_error=True)\n",
    "import llamas_pyjamas.Trace.traceLlamasMulti as trace # type: ignore\n",
    "import llamas_pyjamas.Extract.extractLlamas as extract # type: ignore\n",
    "from llamas_pyjamas.Image.WhiteLight import WhiteLight, WhiteLightFits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get absolute path to llamas_pyjamas package\n",
    "package_path = pkg_resources.resource_filename('llamas_pyjamas', '')\n",
    "package_root = os.path.dirname(package_path)\n",
    "\n",
    "print(f\"Package path: {package_path}\")\n",
    "print(f\"Package root: {package_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional Ray initialisation if attempting to parallelise some of the processes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Ray runtime environment\n",
    "runtime_env = {\n",
    "    \"py_modules\": [package_root],\n",
    "    \"env_vars\": {\"PYTHONPATH\": f\"{package_root}:{os.environ.get('PYTHONPATH', '')}\"},\n",
    "    \"excludes\": [\n",
    "        str(Path(DATA_DIR) / \"**\"),  # Exclude DATA_DIR and all subdirectories\n",
    "        \"**/*.fits\",                 # Exclude all FITS files anywhere\n",
    "        \"**/*.gz\",                 # Exclude all tarballs files anywhere\n",
    "        \"**/*.zip\",                 # Exclude all zip files anywhere\n",
    "        \"**/*.pkl\",                  # Exclude all pickle files anywhere\n",
    "        \"**/.git/**\",               # Exclude git directory\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Initialize Ray\n",
    "ray.shutdown()\n",
    "ray.init(runtime_env=runtime_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/Users/simcoe/Science/LLAMAS/CommissioningRun/NIGHT5\"\n",
    "import importlib\n",
    "importlib.reload(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the extraction process on a single fits image and then plot a single spectrum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llamas_pyjamas.GUI.guiExtract import GUI_extract\n",
    "filepath = 'Path_to_your_fits_file'\n",
    "filepath = '/Users/slh/Documents/Projects/Magellan_dev/LLAMAS/comissioning_data/20241128/LLAMAS_2024-11-28T03_50_39.584_mef.fits'\n",
    "# Example: filepath = '/Users/slh/Documents/Projects/Magellan_dev/LLAMAS/comissioning_data/20241128/LLAMAS_2024-11-28T03_50_39.584_mef.fits\n",
    " \n",
    "GUI_extract(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This should take a few mintues to run and in your output folder you should see the extracted pickle file\n",
    "extract_pickle = 'output/your_extraction_file.pkl'\n",
    "extract_pickle = '/Users/slh/Documents/Projects/Magellan_dev/LLAMAS/llamas-pyjamas/llamas_pyjamas/output/LLAMASExtract_batch_20250203_215658.pkl'\n",
    "#Example: extract_pickle = '/Users/slh/Documents/Projects/Magellan_dev/LLAMAS/llamas-pyjamas/llamas_pyjamas/output/LLAMASExtract_batch_20250203_215658.pkl'\n",
    "\n",
    "with open(extract_pickle, 'rb') as f:\n",
    "    exobj = pickle.load(f)\n",
    "\n",
    "extraction_list = exobj['extractions']\n",
    "\n",
    "#select which extraction object you wish to plot\n",
    "# Each object represents a single HDU extension in the FITS file which was extracted. \n",
    "# The order should correspond to the orider in the fits file\n",
    "\n",
    "HDU_idx = 0 #change the '0' to the value of the HDU you wish to plot spectra from\n",
    "spec_arrays = extraction_list[HDU_idx].counts #change the '0' to the value of the HDU you wish to plot spectra from\n",
    "\n",
    "#This gives you an array of the extracted spectra for the selected HDU, shape = (Nfib, 2048)\n",
    "#You can plot the spectra for a single fiber using the following code\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "Nfib = 0 #select the fiber you wish to plot\n",
    "plt.plot(spec_arrays[Nfib])\n",
    "plt.show()\n",
    "\n",
    "#To load in the extracted pickle file and plot the spectra for a single fiber\n",
    "\n",
    "# then follow the steps from the exobjs line onwards\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the extraction on a single HDU extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llamas_pyjamas.Extract.extractLlamas import ExtractLlamas\n",
    "import pickle\n",
    "from astropy.io import fits\n",
    "\n",
    "### MAKE SURE THE COLOUR AND BENCHSIDE OF THE TRACEFILE YOU LOAD IN MATCHES THE HDU YOU WANT TO EXTRACT\n",
    "#e.g. red_1A typically corresponds to hdu[1] in the fits file\n",
    "#To check this print hdu[i].header\n",
    "with open(DATA_DIR + '/Your_trace_file.pkl', 'rb') as f:\n",
    "    traceobj = pickle.load(f)\n",
    "\n",
    "hdu = fits.open('Path_to_your_fits_file.fits')\n",
    "ex = ExtractLlamas(traceobj, hdu[hdu_index].data.astype(float), dict(hdu[hdu_index].header))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the flat field (for getting fiber throughputs later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skyflat_filename = filename\n",
    "trace_filename = os.path.join(DATA_DIR, 'LLAMAS_2024-11-29T23_50_11.041_mef.fits')\n",
    "extract.ExtractLlamasCube(skyflat_filename, trace_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract an arc frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(extract)\n",
    "arc_filename   = os.path.join(DATA_DIR, 'LLAMAS_2024-11-29T23_07_53.063_mef.fits')\n",
    "extract.ExtractLlamasCube(arc_filename, trace_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in and plot up arc extractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_picklename = os.path.join(OUTPUT_DIR, os.path.basename(arc_filename).replace('_mef.fits', '_extract.pkl'))\n",
    "arcspec, metadata = extract.load_extractions(arc_picklename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import llamas_pyjamas.Arc.arcLlamas as arc\n",
    "importlib.reload(arc)\n",
    "arc.shiftArcX(arc_picklename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "shift_picklename = arc_picklename.replace('_extract.pkl', '_extract_shifted.pkl')\n",
    "arcspec_shifted, metadata_shifted = extract.load_extractions(shift_picklename)\n",
    "[plt.plot(arcspec_shifted[18].xshift[i,:], arcspec_shifted[18].counts[i,:],\".\") for i in range(100,200)]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(arcspec_shifted[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(metadata)\n",
    "plt.plot(arcspec[12].counts[150])\n",
    "plt.plot(arcspec[0].counts[150])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypeit.core.wavecal.wvutils import xcorr_shift_stretch\n",
    "func = 'quadratic'\n",
    "fiber = 200\n",
    "success, shift, stretch, stretch2, _, _, _ = xcorr_shift_stretch(arcspec[1].counts[fiber], arcspec[7].counts[150], stretch_func=func)\n",
    "print(success, shift, stretch, stretch2)\n",
    "x = np.arange(2048)\n",
    "plt.plot((x*stretch+x**2*stretch2)+shift, arcspec[7].counts[150])\n",
    "plt.plot(x, arcspec[1].counts[fiber])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcspec[10].trace.fiberimg\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamas_data_reduction_clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
